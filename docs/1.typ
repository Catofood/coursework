#import "lib/gost.typ": *
#import "lib/titlepage.typ": *

#show: doc => init(doc)

#ch("ВВЕДЕНИЕ")

Актуальность разработки аналитического микросервиса для Telegram-бота расписания ГУАП обусловлена растущей необходимостью отслеживания и анализа использования информационной системы. Миграция бота на облачную инфраструктуру и его интеграция с микросервисной архитектурой требует разработки специализированного сервиса для сбора, хранения и анализа метрик использования.

Целью работы является разработка микросервиса аналитики, который обеспечивает сбор событий использования бота в реальном времени через Kafka, хранение структурированных данных о пользователях, запросах и событиях обновления, предоставление REST API для получения статистики использования бота и интеграцию с основным сервисом SuaiScheduleBot через асинхронную очередь сообщений.

Задачи работы включают анализ предметной области и выявление требований, проектирование архитектуры микросервиса с использованием принципов Clean Architecture, реализацию слоев Domain, Application, Infrastructure и API, разработку компонентов для потребления событий из Kafka, создание репозиториев и запросов к базе данных PostgreSQL, разработку и тестирование API endpoints для получения аналитики, документирование кода и написание пояснительной записки.
#pagebreak()

= Анализ предметной области

== Первичная постановка задачи

Разрабатываемый микросервис SuaiScheduleBotAnalytics предназначен для сбора, обработки и предоставления статистики использования Telegram-бота расписания ГУАП. Основной сервис SuaiScheduleBot при выполнении пользовательских действий (просмотр расписания, подписка на группу и т.д.) отправляет сообщения в очередь Kafka. Сервис аналитики должен потреблять эти события и сохранять их в базе данных для последующего анализа.

Требования к системе: сбор событий от основного бота в реальном времени; хранение информации о пользователях, группах, запросах и обновлениях; предоставление API для получения различных метрик и статистики; поддержка фильтрации данных по временным периодам; обеспечение надежности и масштабируемости системы; соответствие принципам Clean Architecture для обеспечения maintainability.
\ 

== Анализ предметной области

В контексте разработки данной системы ключевыми понятиями являются:

*Пользователь* — зарегистрированный пользователь Telegram, взаимодействующий с ботом расписания. Каждый пользователь идентифицируется уникальным Telegram ID и содержит информацию о дате регистрации, предпочитаемой группе и истории запросов.

*Группа* — академическая группа ГУАП (например, М411, М412 и т.д.). Пользователи могут просматривать расписание различных групп и подписываться на избранные группы.

*Запрос пользователя* — действие пользователя в боте, включающее просмотр расписания для конкретной группы. Каждый запрос содержит тип запроса, временную метку, ссылку на пользователя и группу.

*Событие обновления* — событие, возникающее при обновлении информации о пользователе (например, при подписке на новую группу). Хранит тип события, пользователя и группу.

*Метрика* — агрегированные данные о использовании системы, включая количество пользователей, популярные группы, пиковые часы использования.

Проблема, решаемая данным микросервисом: основной бот генерирует большое количество событий, которые требуют обработки, хранения и анализа. Централизованный микросервис аналитики позволяет отделить логику сбора метрик от основной логики бота, обеспечивая лучшую масштабируемость и производительность системы.
\ 

== Анализ возможных методов решения
=== Архитектурные подходы

При разработке микросервиса были рассмотрены следующие архитектурные подходы:

*Монолитная архитектура* -- интеграция модуля аналитики непосредственно в основной бот. Преимущества: простота развертывания, прямой доступ к данным. Недостатки: увеличение связанности кода, сложность масштабирования, влияние на производительность основного сервиса.

*Микросервисная архитектура* (выбранный вариант) -- отдельный независимый сервис для аналитики, взаимодействующий с основным ботом через асинхронную очередь Kafka. Преимущества: разделение ответственности, независимая масштабируемость, асинхронная обработка не влияет на основной сервис. Недостатки: повышенная сложность развертывания, необходимость управления распределенными транзакциями.

*Real-time streaming* -- использование Apache Kafka Streams или Event Sourcing для обработки событий. Преимущества: высокая производительность, возможность обработки больших объемов данных. Недостатки: сложность разработки, требует специализированных знаний.

Выбранный вариант (микросервисная архитектура) обеспечивает оптимальный баланс между простотой разработки, масштабируемостью и отделением ответственности.
\ 
=== Технологические решения

*Фреймворк и язык* -- ASP.NET Core 9 с языком C\# был выбран за счет встроенной поддержки внедрения зависимостей (DI), наличия удобных библиотек для работы с Kafka (MassTransit), хорошей производительности и экосистемы, удобства разработки и мощных инструментов.

*Управление данными* -- Entity Framework Core (EF Core) с PostgreSQL обеспечивает объектно-реляционное отображение (ORM), миграции БД, поддержку сложных запросов и транзакционность.

*Потребление событий* -- MassTransit + Kafka обеспечивает гибкую конфигурацию потребителей, автоматическое управление подписками, поддержку retry-логики и легкую интеграцию с DI контейнером.

*Паттерны проектирования* -- Clean Architecture (без DDD) обеспечивает четкое разделение слоев, независимость от деталей реализации, облегчает тестирование и упрощает поддержку и расширение.
\ 

== Цель разработки

Создание масштабируемого микросервиса для сбора и анализа метрик использования Telegram-бота расписания ГУАП, обеспечивающий асинхронную обработку событий без влияния на производительность основного сервиса.

== Основные задачи

+ Проектирование архитектуры микросервиса включает разделение логики на четыре слоя: Domain, Application, Infrastructure и WebApi, в соответствии с принципами Clean Architecture.

+ Определение доменных моделей (UserEntity, GroupEntity, RequestEntity, UpdateEntity) и их отношений в системе для правильного представления бизнес-сущностей.

+ Реализация потребителей Kafka (UserPerformedRequestConsumer, UserUpdatedMessageConsumer) для асинхронной обработки событий от основного бота без нарушения его производительности.

+ Разработка репозиториев и абстракций доступа к данным для операций создания, чтения и фильтрации данных из базы.

+ Создание REST API endpoints (StatisticsController) с использованием MediatR для обработки запросов статистики и предоставления метрик администраторам.

+ Обеспечение интеграции с PostgreSQL через Entity Framework Core с поддержкой миграций баз данных и оптимизацией LINQ запросов.

+ Реализация валидации входных данных и обработки ошибок на уровне Application слоя с выбросом типизированных исключений.

+ Разработка Docker Compose конфигурации для упрощения локальной разработки и production развертывания микросервиса.

+ Создание полной документации REST API через Swagger/OpenAPI с описанием всех endpoints, параметров и примеров ответов.

+ Проведение комплексного тестирования компонентов и интеграционных тестов для обеспечения качества реализации всех требований.